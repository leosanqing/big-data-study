# 1. Fluss

``` sql
CREATE CATALOG fluss_catalog WITH (
  'type' = 'fluss',
  'bootstrap.servers' = 'bigdata01:9123'
);


USE CATALOG fluss_catalog;

nohup ./hive --service metastore &
nohup ./hive --service hiveserver2 &

drop table if exists pk_table09;
CREATE TABLE pk_table14 (
  shop_id BIGINT,
  user_id BIGINT,
  num_orders INT,
  total_amount INT,
  PRIMARY KEY (shop_id, user_id) NOT ENFORCED
) WITH (
  'bucket.num' = '3'
);


SET 'execution.runtime-mode' = 'batch';
SET 'execution.runtime-mode' = 'streaming';

SET 'sql-client.execution.result-mode' = 'tableau';

INSERT INTO pk_table14 VALUES
  (1234, 1234, 1, 1),
  (12345, 12345, 2, 2),
  (123456, 123456, 3, 3);
```

# 3.异常
## 3.1 找不到表

```shell
2025-08-01 16:41:54,461 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_fluss_catalog.fluss.pk_table (a5e279820b5461b4a94db6081a9bf095) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:176) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:107) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:285) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:276) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:269) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:764) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:741) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:488) ~[flink-dist-1.18.1.jar:1.18.1]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_361]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_361]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_361]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_361]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:309) ~[flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:307) ~[flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:222) ~[flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:85) ~[flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:168) ~[flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:280) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:241) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:253) [flink-rpc-akka98cd8e78-d34f-4007-b866-0eb03a8f330c.jar:1.18.1]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289) [?:1.8.0_361]
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1067) [?:1.8.0_361]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1703) [?:1.8.0_361]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:172) [?:1.8.0_361]
Caused by: java.lang.IllegalArgumentException: table: fluss.pk_table not found in cluster
	at com.alibaba.fluss.cluster.Cluster.lambda$getTableOrElseThrow$2(Cluster.java:244) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at java.util.Optional.orElseThrow(Optional.java:290) ~[?:1.8.0_361]
	at com.alibaba.fluss.cluster.Cluster.getTableOrElseThrow(Cluster.java:241) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.metadata.MetadataUpdater.getTableInfoOrElseThrow(MetadataUpdater.java:99) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.FlussConnection.getTable(FlussConnection.java:103) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.sink.writer.FlinkSinkWriter.initialize(FlinkSinkWriter.java:112) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.sink.writer.UpsertSinkWriter.initialize(UpsertSinkWriter.java:61) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.sink.FlinkSink.createWriter(FlinkSink.java:63) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at org.apache.flink.streaming.runtime.operators.sink.StatelessSinkWriterStateHandler.createWriter(StatelessSinkWriterStateHandler.java:39) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.operators.sink.SinkWriterOperator.initializeState(SinkWriterOperator.java:149) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.initializeOperatorState(StreamOperatorStateHandler.java:122) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:274) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.initializeStateAndOpenOperators(RegularOperatorChain.java:106) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.restoreGates(StreamTask.java:753) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.call(StreamTaskActionExecutor.java:55) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.restoreInternal(StreamTask.java:728) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.restore(StreamTask.java:693) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:953) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:922) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:746) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.18.1.jar:1.18.1]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_361]
```



```bash
2025-08-04 10:36:19,204 DEBUG com.alibaba.fluss.rpc.netty.client.NettyClient               [] - Creating connection to server bigdata01:9123 (id: cs--1, rack: null).
2025-08-04 10:36:19,207 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.channel.DefaultChannelId [] - -Dio.netty.processId: 512129 (auto-detected)
2025-08-04 10:36:19,208 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.NetUtil        [] - -Djava.net.preferIPv4Stack: false
2025-08-04 10:36:19,208 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.NetUtil        [] - -Djava.net.preferIPv6Addresses: false
2025-08-04 10:36:19,208 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.NetUtilInitializations [] - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-08-04 10:36:19,209 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.NetUtil        [] - /proc/sys/net/core/somaxconn: 4096
2025-08-04 10:36:19,209 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.channel.DefaultChannelId [] - -Dio.netty.machineId: 00:1c:42:ff:fe:35:8d:77 (auto-detected)
2025-08-04 10:36:19,218 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.buffer.ByteBufUtil  [] - -Dio.netty.allocator.type: pooled
2025-08-04 10:36:19,218 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.buffer.ByteBufUtil  [] - -Dio.netty.threadLocalDirectBufferSize: 0
2025-08-04 10:36:19,218 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.buffer.ByteBufUtil  [] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-08-04 10:36:19,220 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.bootstrap.ChannelInitializerExtensions [] - -Dio.netty.bootstrap.extensions: null
2025-08-04 10:36:19,231 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1] REGISTERED
2025-08-04 10:36:19,231 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1] CONNECT: bigdata01/10.211.55.5:9123
2025-08-04 10:36:19,232 DEBUG com.alibaba.fluss.rpc.netty.client.ServerConnection          [] - Established connection to server bigdata01:9123 (id: cs--1, rack: null).
2025-08-04 10:36:19,232 DEBUG com.alibaba.fluss.rpc.netty.client.ServerConnection          [] - switch state form CONNECTING to CHECKING_API_VERSIONS
2025-08-04 10:36:19,234 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.Recycler       [] - -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-08-04 10:36:19,234 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.Recycler       [] - -Dio.netty.recycler.ratio: 8
2025-08-04 10:36:19,234 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.Recycler       [] - -Dio.netty.recycler.chunkSize: 32
2025-08-04 10:36:19,234 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.Recycler       [] - -Dio.netty.recycler.blocking: false
2025-08-04 10:36:19,234 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.Recycler       [] - -Dio.netty.recycler.batchFastThreadLocalOnly: true
2025-08-04 10:36:19,238 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.buffer.AbstractByteBuf [] - -Dcom.alibaba.fluss.shaded.netty4.io.netty.buffer.checkAccessible: true
2025-08-04 10:36:19,238 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.buffer.AbstractByteBuf [] - -Dcom.alibaba.fluss.shaded.netty4.io.netty.buffer.checkBounds: true
2025-08-04 10:36:19,305 DEBUG com.alibaba.fluss.shaded.netty4.io.netty.util.ResourceLeakDetectorFactory [] - Loaded default ResourceLeakDetector: com.alibaba.fluss.shaded.netty4.io.netty.util.ResourceLeakDetector@30c213d5
2025-08-04 10:36:19,308 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] WRITE 26B
2025-08-04 10:36:19,308 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] FLUSH
2025-08-04 10:36:19,309 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] ACTIVE
2025-08-04 10:36:19,314 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] READ 270B
2025-08-04 10:36:19,320 DEBUG com.alibaba.fluss.rpc.netty.client.ServerConnection          [] - Begin to authenticate with protocol PLAINTEXT
2025-08-04 10:36:19,320 DEBUG com.alibaba.fluss.rpc.netty.client.ServerConnection          [] - switch state form CHECKING_API_VERSIONS to READY
2025-08-04 10:36:19,320 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] WRITE 14B
2025-08-04 10:36:19,320 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] FLUSH
2025-08-04 10:36:19,320 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] READ COMPLETE
2025-08-04 10:36:19,322 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] READ 48B
2025-08-04 10:36:19,324 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x94c7e0f1, L:/10.211.55.6:49788 - R:bigdata01/10.211.55.5:9123] READ COMPLETE
2025-08-04 10:36:19,324 DEBUG com.alibaba.fluss.rpc.netty.client.NettyClient               [] - Creating connection to server 127.0.0.1:34079 (id: ts-0, rack: null).
2025-08-04 10:36:19,325 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x25cbba13] REGISTERED
2025-08-04 10:36:19,325 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x25cbba13] CONNECT: /127.0.0.1:34079
2025-08-04 10:36:19,325 ERROR com.alibaba.fluss.rpc.netty.client.ServerConnection          [] - Failed to establish connection to server 127.0.0.1:34079 (id: ts-0, rack: null).
com.alibaba.fluss.shaded.netty4.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /127.0.0.1:34079
Caused by: java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_361]
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:715) ~[?:1.8.0_361]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:335) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at java.lang.Thread.run(Thread.java:750) [?:1.8.0_361]
2025-08-04 10:36:19,328 DEBUG com.alibaba.fluss.rpc.netty.client.ServerConnection          [] - switch state form CONNECTING to DISCONNECTED
2025-08-04 10:36:19,328 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x25cbba13] CLOSE
2025-08-04 10:36:19,329 WARN  com.alibaba.fluss.client.metadata.MetadataUpdater            [] - Failed to update metadata, but the exception is re-triable.
com.alibaba.fluss.exception.NetworkException: Disconnected from node 127.0.0.1:34079 (id: ts-0, rack: null)
Caused by: com.alibaba.fluss.shaded.netty4.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /127.0.0.1:34079
Caused by: java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_361]
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:715) ~[?:1.8.0_361]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:335) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.shaded.netty4.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at java.lang.Thread.run(Thread.java:750) [?:1.8.0_361]
2025-08-04 10:36:19,329 DEBUG com.alibaba.fluss.rpc.netty.NettyLogger                      [] - [id: 0x25cbba13] UNREGISTERED
2025-08-04 10:36:19,329 DEBUG org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Cleanup StreamTask (operators closed: false, cancelled: false)
2025-08-04 10:36:19,330 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - pk_table[6]: Writer (1/1)#0 (54a6986a8b0295652039ba112446cd58_306d8342cb5b2ad8b53f1be57f65bee8_0_0) switched from INITIALIZING to FAILED with failure cause:
java.lang.IllegalArgumentException: table: fluss.pk_table not found in cluster
        at com.alibaba.fluss.cluster.Cluster.lambda$getTableOrElseThrow$2(Cluster.java:244) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at java.util.Optional.orElseThrow(Optional.java:290) ~[?:1.8.0_361]
        at com.alibaba.fluss.cluster.Cluster.getTableOrElseThrow(Cluster.java:241) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        at com.alibaba.fluss.client.metadata.MetadataUpdater.getTableInfoOrElseThrow(MetadataUpdater.java:99) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
        
```



## 3.2 JVM 不匹配 NIO 报错

```bash
Caused by: java.lang.NoSuchMethodError: java.nio.ByteBuffer.limit(I)Ljava/nio/ByteBuffer;
	at com.alibaba.fluss.utils.ByteBufferReadableChannel.read(ByteBufferReadableChannel.java:57) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.vector.ipc.ReadChannel.readFully(ReadChannel.java:60) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.vector.ipc.message.MessageSerializer.readMessage(MessageSerializer.java:683) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.vector.ipc.message.MessageSerializer.deserializeRecordBatch(MessageSerializer.java:355) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.utils.ArrowUtils.createArrowReader(ArrowUtils.java:160) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.record.DefaultLogRecordBatch.columnRecordIterator(DefaultLogRecordBatch.java:331) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.record.DefaultLogRecordBatch.records(DefaultLogRecordBatch.java:245) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.CompletedFetch.nextFetchedRecord(CompletedFetch.java:220) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.CompletedFetch.fetchRecords(CompletedFetch.java:170) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.LogFetchCollector.fetchRecords(LogFetchCollector.java:160) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.LogFetchCollector.collectFetch(LogFetchCollector.java:118) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.LogFetcher.collectFetch(LogFetcher.java:163) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.LogScannerImpl.pollForFetches(LogScannerImpl.java:234) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.client.table.scanner.log.LogScannerImpl.poll(LogScannerImpl.java:144) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.fetch(FlinkSourceSplitReader.java:165) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at org.apache.flink.connector.base.source.reader.fetcher.FetchTask.run(FetchTask.java:58) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_361]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_361]
	... 1 more


---- 必须使用 JDK 17，但是默认加载到了 JDK8

2025-08-05 10:02:27,853 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  OS current user: parallels
2025-08-05 10:02:27,957 WARN  org.apache.hadoop.util.NativeCodeLoader                      [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-05 10:02:27,995 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Current Hadoop/Kerberos user: parallels
2025-08-05 10:02:27,995 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.361-b09
```

原因是 `/etc/profile`中配置的默认使用 jdk8

## 3.3 snapshot 找不到



```shell
2025-08-05 10:32:07,672 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: pk_table01[4] -> ConstraintEnforcer[5] -> Sink: Collect table sink (1/1) (34300f6d721719fa11f7a22b725d4020_cbc357ccb763df2852fee8c4fc7d55f2_0_8) switched from RUNNING to FAILED on container_1752656188192_0009_01_000002 @ bigdata03 (dataPort=40855).
java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:263) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:185) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:147) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:419) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:562) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:858) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:807) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:953) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:932) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:746) ~[flink-dist-1.18.1.jar:1.18.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.18.1.jar:1.18.1]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_361]
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception while polling the records
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:168) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_361]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_361]
	... 1 more
Caused by: com.alibaba.fluss.exception.FlussRuntimeException: Failed to get snapshot metadata
	at com.alibaba.fluss.client.table.scanner.TableScan.createBatchScanner(TableScan.java:127) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.checkSnapshotSplitOrStartNext(FlinkSourceSplitReader.java:375) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.fetch(FlinkSourceSplitReader.java:143) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at org.apache.flink.connector.base.source.reader.fetcher.FetchTask.run(FetchTask.java:58) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_361]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_361]
	... 1 more
Caused by: java.util.concurrent.ExecutionException: com.alibaba.fluss.exception.KvSnapshotNotExistException: Failed to get kv snapshot metadata for table bucket TableBucket{tableId=5, bucket=0} and snapshot id 0. Error: /tmp/fluss-remote-data/kv/fluss/pk_table01-5/0/snap-0/_METADATA (No such file or directory)
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_361]
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908) ~[?:1.8.0_361]
	at com.alibaba.fluss.client.table.scanner.TableScan.createBatchScanner(TableScan.java:125) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.checkSnapshotSplitOrStartNext(FlinkSourceSplitReader.java:375) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.fetch(FlinkSourceSplitReader.java:143) ~[fluss-flink-1.18-0.8-SNAPSHOT.jar:0.8-SNAPSHOT]
	at org.apache.flink.connector.base.source.reader.fetcher.FetchTask.run(FetchTask.java:58) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117) ~[flink-connector-files-1.18.1.jar:1.18.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_361]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_361]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_361]
	... 1 more
Caused by: com.alibaba.fluss.exception.KvSnapshotNotExistException: Failed to get kv snapshot metadata for table bucket TableBucket{tableId=5, bucket=0} and snapshot id 0. Error: /tmp/fluss-remote-data/kv/fluss/pk_table01-5/0/snap-0/_METADATA (No such file or directory)

```

如果 fluss 是分布式， remote Data dir 必须也配置为 hdfs 这种 dfs, meta 在 local 机器，但是 data 在 remote 机器，不在一个机器，默认找本地机器上文件，导致找不到文件

```yaml
remote.data.dir: hdfs://bigdata01:9000/fluss-remote-data
```

## 3.4 查询报错 还是 JDK 模块问题

```shell
2025-08-06 14:39:21,805 DEBUG org.apache.flink.runtime.jobmaster.JobMaster                 [] - Archive local failure causing attempt 8345680afb9428c5eb06cea1586ea2c0_cbc357ccb763df2852fee8c4fc7d55f2_0_28 to fail: java.lang.RuntimeException: One or more fetchers have encountered exception
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:263)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:185)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:147)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:419)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:562)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:858)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:807)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:953)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:932)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:746)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NoClassDefFoundError: Could not initialize class com.alibaba.fluss.shaded.arrow.org.apache.arrow.memory.util.MemoryUtil
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.memory.ArrowBuf.getDirectBuffer(ArrowBuf.java:229)
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.memory.ArrowBuf.nioBuffer(ArrowBuf.java:224)
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.vector.ipc.ReadChannel.readFully(ReadChannel.java:87)
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.vector.ipc.message.MessageSerializer.readMessageBody(MessageSerializer.java:728)
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.vector.ipc.message.MessageSerializer.deserializeRecordBatch(MessageSerializer.java:363)
	at com.alibaba.fluss.utils.ArrowUtils.createArrowReader(ArrowUtils.java:160)
	at com.alibaba.fluss.record.DefaultLogRecordBatch.columnRecordIterator(DefaultLogRecordBatch.java:331)
	at com.alibaba.fluss.record.DefaultLogRecordBatch.records(DefaultLogRecordBatch.java:245)
	at com.alibaba.fluss.client.table.scanner.log.CompletedFetch.nextFetchedRecord(CompletedFetch.java:220)
	at com.alibaba.fluss.client.table.scanner.log.CompletedFetch.fetchRecords(CompletedFetch.java:170)
	at com.alibaba.fluss.client.table.scanner.log.LogFetchCollector.fetchRecords(LogFetchCollector.java:160)
	at com.alibaba.fluss.client.table.scanner.log.LogFetchCollector.collectFetch(LogFetchCollector.java:118)
	at com.alibaba.fluss.client.table.scanner.log.LogFetcher.collectFetch(LogFetcher.java:163)
	at com.alibaba.fluss.client.table.scanner.log.LogScannerImpl.pollForFetches(LogScannerImpl.java:234)
	at com.alibaba.fluss.client.table.scanner.log.LogScannerImpl.poll(LogScannerImpl.java:144)
	at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.fetch(FlinkSourceSplitReader.java:165)
	at org.apache.flink.connector.base.source.reader.fetcher.FetchTask.run(FetchTask.java:58)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:117)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	... 1 more
	Suppressed: java.lang.IllegalStateException: Memory was leaked by query. Memory leaked: (128)
Allocator(ROOT) 0/128/128/9223372036854775807 (res/actual/peak/limit)

		at com.alibaba.fluss.shaded.arrow.org.apache.arrow.memory.BaseAllocator.close(BaseAllocator.java:477)
		at com.alibaba.fluss.shaded.arrow.org.apache.arrow.memory.RootAllocator.close(RootAllocator.java:29)
		at com.alibaba.fluss.record.LogRecordReadContext.close(LogRecordReadContext.java:223)
		at com.alibaba.fluss.client.table.scanner.log.LogFetcher.close(LogFetcher.java:500)
		at com.alibaba.fluss.client.table.scanner.log.LogScannerImpl.close(LogScannerImpl.java:298)
		at com.alibaba.fluss.flink.source.reader.FlinkSourceSplitReader.close(FlinkSourceSplitReader.java:532)
		at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:124)
		... 5 more
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.RuntimeException: Failed to initialize MemoryUtil. You must start Java with `--add-opens=java.base/java.nio=ALL-UNNAMED` (See https://arrow.apache.org/docs/java/install.html) [in thread "Source Data Fetcher for Source: pk_table02[1] -> ConstraintEnforcer[2] -> Sink: Collect table sink (1/1)#0"]
	at com.alibaba.fluss.shaded.arrow.org.apache.arrow.memory.util.MemoryUtil.<clinit>(MemoryUtil.java:143)
	... 24 more
```



## 3.5 一直加载的是 jdk8

明明设置 jdk17 还是加载 jdk8

原因：`/opt/software/hadoop-3.2.4/etc/hadoop/hadoop-env.sh` 里面指定了 JAVA_HOME ，重新设置，并且开放模块

```yaml

# 你自己jdk的保存位置，也是你配置jdk环境变量时的java_home的值
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64
export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"  # 这个是后面我遇到问题加的，建议直接加上



# 为 ResourceManager 添加 JVM 启动参数以兼容 Java 11+
# 这会向 JVM 明确指出，允许“所有未命名模块”的代码访问 java.base 模块中的 java.lang 包
export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS --add-opens=java.base/java.lang=ALL-UNNAMED"
export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS --add-opens=java.base/java.net=ALL-UNNAMED"
export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS --add-opens=java.base/java.nio=ALL-UNNAMED"
export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS --add-opens=java.base/java.util=ALL-UNNAMED"
export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS --add-opens=java.base/java.util.concurrent=ALL-UNNAMED"

export YARN_RESOURCEMANAGER_OPTS="$YARN_RESOURCEMANAGER_OPTS --add-opens=java.base/java.nio=ALL-UNNAMED

```

